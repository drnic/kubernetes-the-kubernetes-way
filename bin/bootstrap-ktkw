#!/bin/bash

set -eu

MASTERS=${MASTERS:-1}
WORKERS=${WORKERS:-0}
REGION=$(gcloud config get-value compute/region)

DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" && pwd )"

[[ -z ${SKIP_GCLOUD:-} ]] && {
(
  set -x
  gcloud compute networks create kubernetes-the-kubernetes-way --subnet-mode custom || echo skipping...
  gcloud compute networks subnets create kubernetes \
    --network kubernetes-the-kubernetes-way \
    --range 10.240.0.0/24 || echo skipping...
  gcloud compute firewall-rules create kubernetes-the-kubernetes-way-allow-internal \
    --allow tcp,udp,icmp \
    --network kubernetes-the-kubernetes-way \
    --source-ranges 10.240.0.0/24,10.200.0.0/16 || echo skipping...
  gcloud compute firewall-rules create kubernetes-the-kubernetes-way-allow-external \
    --allow tcp:22,tcp:6443,icmp \
    --network kubernetes-the-kubernetes-way \
    --source-ranges 0.0.0.0/0 || echo skipping...
  gcloud compute addresses create kubernetes-the-kubernetes-way \
    --region "$REGION" || echo skipping...
)

i=0
while [ $i -lt $MASTERS ]; do
  (
  set -x
  gcloud compute instances create controller-${i} \
    --async \
    --boot-disk-size 200GB \
    --can-ip-forward \
    --image-family ubuntu-1804-lts \
    --image-project ubuntu-os-cloud \
    --machine-type n1-standard-1 \
    --metadata pod-cidr=10.200.${i}.0/24 \
    --private-network-ip 10.240.0.1${i} \
    --scopes compute-rw,storage-ro,service-management,service-control,logging-write,monitoring \
    --subnet kubernetes \
    --tags kubernetes-the-kubernetes-way,controller || echo skipping...
  )
  ((i++))
done

i=0
while [ $i -lt $WORKERS ]; do
  (
  cidr_range=$((20+i))
  set -x
  gcloud compute instances create worker-${i} \
    --async \
    --boot-disk-size 200GB \
    --can-ip-forward \
    --image-family ubuntu-1804-lts \
    --image-project ubuntu-os-cloud \
    --machine-type n1-standard-1 \
    --metadata pod-cidr=10.200.${cidr_range}.0/24 \
    --private-network-ip 10.240.0.2${i} \
    --scopes compute-rw,storage-ro,service-management,service-control,logging-write,monitoring \
    --subnet kubernetes \
    --tags kubernetes-the-kubernetes-way,worker || echo skipping...

  gcloud compute routes create kubernetes-route-10-200-${i}-0-24 \
    --network kubernetes-the-kubernetes-way \
    --next-hop-address 10.240.0.2${i} \
    --destination-range 10.200.${i}.0/24 || echo skipping...
  )
  ((i++))
done
}

(
  set -x
  gcloud compute instances list
)

[[ -n ${JUST_VMS:-} ]] && { exit 0; }

KUBERNETES_PUBLIC_ADDRESS=$(gcloud compute addresses describe kubernetes-the-kubernetes-way \
  --region $(gcloud config get-value compute/region) \
  --format 'value(address)')

[[ -f ca.crt ]] || {

cat > ca-config.json <<EOF
{
  "signing": {
    "default": {
      "expiry": "8760h"
    },
    "profiles": {
      "kubernetes": {
        "usages": ["signing", "key encipherment", "server auth", "client auth"],
        "expiry": "8760h"
      }
    }
  }
}
EOF

cat > ca-csr.json <<EOF
{
  "CN": "Kubernetes",
  "key": {
    "algo": "rsa",
    "size": 2048
  },
  "names": [
    {
      "C": "AU",
      "L": "Brisbane",
      "O": "Kubernetes",
      "OU": "CA",
      "ST": "Queensland"
    }
  ]
}
EOF

cfssl gencert -initca ca-csr.json | cfssljson -bare ca
mv ca.pem ca.crt
mv ca-key.pem ca.key
}

[[ -f admin-key.pem ]] || {
  cat > admin-csr.json <<EOF
{
  "CN": "admin",
  "key": {
    "algo": "rsa",
    "size": 2048
  },
  "names": [
    {
      "C": "AU",
      "L": "Brisbane",
      "O": "system:masters",
      "OU": "Kubernetes The Kubernetes Way",
      "ST": "Queensland"
    }
  ]
}
EOF

cfssl gencert \
  -ca=ca.crt \
  -ca-key=ca.key \
  -config=ca-config.json \
  -profile=kubernetes \
  admin-csr.json | cfssljson -bare admin

}

i=0
while [ $i -lt $WORKERS ]; do
  instance=worker-$i
  [[ -f ${instance}.pem ]] || {
    cat > ${instance}-csr.json <<EOF
{
  "CN": "system:node:${instance}",
  "key": {
    "algo": "rsa",
    "size": 2048
  },
  "names": [
    {
      "C": "AU",
      "L": "Brisbane",
      "O": "system:nodes",
      "OU": "Kubernetes The Kubernetes Way",
      "ST": "Queensland"
    }
  ]
}
EOF

    EXTERNAL_IP=$(gcloud compute instances describe ${instance} \
      --format 'value(networkInterfaces[0].accessConfigs[0].natIP)')

    INTERNAL_IP=$(gcloud compute instances describe ${instance} \
      --format 'value(networkInterfaces[0].networkIP)')

    cfssl gencert \
      -ca=ca.crt \
      -ca-key=ca.key \
      -config=ca-config.json \
      -hostname=${instance},${EXTERNAL_IP},${INTERNAL_IP} \
      -profile=kubernetes \
      ${instance}-csr.json | cfssljson -bare ${instance}

  }
  ((i++))
done

[[ -f kube-controller-manager.pem ]] || {
  cat > kube-controller-manager-csr.json <<EOF
{
  "CN": "system:kube-controller-manager",
  "key": {
    "algo": "rsa",
    "size": 2048
  },
  "names": [
    {
      "C": "AU",
      "L": "Brisbane",
      "O": "system:kube-controller-manager",
      "OU": "Kubernetes The Kubernetes Way",
      "ST": "Queensland"
    }
  ]
}
EOF

  cfssl gencert \
    -ca=ca.crt \
    -ca-key=ca.key \
    -config=ca-config.json \
    -profile=kubernetes \
    kube-controller-manager-csr.json | cfssljson -bare kube-controller-manager
}

[[ -f kube-proxy.pem ]] || {
  cat > kube-proxy-csr.json <<EOF
{
  "CN": "system:kube-proxy",
  "key": {
    "algo": "rsa",
    "size": 2048
  },
  "names": [
    {
      "C": "AU",
      "L": "Brisbane",
      "O": "system:node-proxier",
      "OU": "Kubernetes The Kubernetes Way",
      "ST": "Queensland"
    }
  ]
}
EOF

  cfssl gencert \
    -ca=ca.crt \
    -ca-key=ca.key \
    -config=ca-config.json \
    -profile=kubernetes \
    kube-proxy-csr.json | cfssljson -bare kube-proxy
}

[[ -f kube-scheduler.pem ]] || {
  cat > kube-scheduler-csr.json <<EOF
{
  "CN": "system:kube-scheduler",
  "key": {
    "algo": "rsa",
    "size": 2048
  },
  "names": [
    {
      "C": "AU",
      "L": "Brisbane",
      "O": "system:kube-scheduler",
      "OU": "Kubernetes The Kubernetes Way",
      "ST": "Queensland"
    }
  ]
}
EOF

  cfssl gencert \
    -ca=ca.crt \
    -ca-key=ca.key \
    -config=ca-config.json \
    -profile=kubernetes \
    kube-scheduler-csr.json | cfssljson -bare kube-scheduler
}

[[ -f kubernetes.pem ]] || {

  KUBERNETES_HOSTNAMES=kubernetes,kubernetes.default,kubernetes.default.svc,kubernetes.default.svc.cluster,kubernetes.svc.cluster.local

  cat > kubernetes-csr.json <<EOF
{
  "CN": "kubernetes",
  "key": {
    "algo": "rsa",
    "size": 2048
  },
  "names": [
    {
      "C": "AU",
      "L": "Brisbane",
      "O": "Kubernetes",
      "OU": "Kubernetes The Kubernetes Way",
      "ST": "Queensland"
    }
  ]
}
EOF

  cfssl gencert \
    -ca=ca.pem \
    -ca-key=ca-key.pem \
    -config=ca-config.json \
    -hostname=10.32.0.1,10.240.0.10,10.240.0.11,10.240.0.12,${KUBERNETES_PUBLIC_ADDRESS},127.0.0.1,${KUBERNETES_HOSTNAMES} \
    -profile=kubernetes \
    kubernetes-csr.json | cfssljson -bare kubernetes

}

[[ -f service-account.pem ]] || {
  cat > service-account-csr.json <<EOF
{
  "CN": "service-accounts",
  "key": {
    "algo": "rsa",
    "size": 2048
  },
  "names": [
    {
      "C": "AU",
      "L": "Brisbane",
      "O": "Kubernetes",
      "OU": "Kubernetes The Kubernetes Way",
      "ST": "Queensland"
    }
  ]
}
EOF

  cfssl gencert \
    -ca=ca.pem \
    -ca-key=ca-key.pem \
    -config=ca-config.json \
    -profile=kubernetes \
    service-account-csr.json | cfssljson -bare service-account

}

KUBERNETES_PUBLIC_ADDRESS=$(gcloud compute addresses describe kubernetes-the-kubernetes-way \
  --region "$REGION" \
  --format 'value(address)')

(
  set -x
  kubectl config set-cluster kubernetes-the-kubernetes-way \
    --certificate-authority=ca.pem \
    --embed-certs=true \
    --server=https://${KUBERNETES_PUBLIC_ADDRESS}:6443 \
    --kubeconfig=kube-proxy.kubeconfig

  kubectl config set-credentials system:kube-proxy \
    --client-certificate=kube-proxy.pem \
    --client-key=kube-proxy-key.pem \
    --embed-certs=true \
    --kubeconfig=kube-proxy.kubeconfig

  kubectl config set-context default \
    --cluster=kubernetes-the-kubernetes-way \
    --user=system:kube-proxy \
    --kubeconfig=kube-proxy.kubeconfig

  kubectl config use-context default --kubeconfig=kube-proxy.kubeconfig

  kubectl config set-cluster kubernetes-the-kubernetes-way \
    --certificate-authority=ca.pem \
    --embed-certs=true \
    --server=https://${KUBERNETES_PUBLIC_ADDRESS}:6443 \
    --kubeconfig=kube-controller-manager.kubeconfig

  kubectl config set-credentials system:kube-controller-manager \
    --client-certificate=kube-controller-manager.pem \
    --client-key=kube-controller-manager-key.pem \
    --embed-certs=true \
    --kubeconfig=kube-controller-manager.kubeconfig

  kubectl config set-context default \
    --cluster=kubernetes-the-kubernetes-way \
    --user=system:kube-controller-manager \
    --kubeconfig=kube-controller-manager.kubeconfig

  kubectl config use-context default --kubeconfig=kube-controller-manager.kubeconfig

  kubectl config set-cluster kubernetes-the-kubernetes-way \
    --certificate-authority=ca.pem \
    --embed-certs=true \
    --server=https://${KUBERNETES_PUBLIC_ADDRESS}:6443 \
    --kubeconfig=kube-scheduler.kubeconfig

  kubectl config set-credentials system:kube-scheduler \
    --client-certificate=kube-scheduler.pem \
    --client-key=kube-scheduler-key.pem \
    --embed-certs=true \
    --kubeconfig=kube-scheduler.kubeconfig

  kubectl config set-context default \
    --cluster=kubernetes-the-kubernetes-way \
    --user=system:kube-scheduler \
    --kubeconfig=kube-scheduler.kubeconfig

  kubectl config use-context default --kubeconfig=kube-scheduler.kubeconfig

  kubectl config set-cluster kubernetes-the-kubernetes-way \
    --certificate-authority=ca.pem \
    --embed-certs=true \
    --server=https://${KUBERNETES_PUBLIC_ADDRESS}:6443 \
    --kubeconfig=admin.kubeconfig

  kubectl config set-credentials admin \
    --client-certificate=admin.pem \
    --client-key=admin-key.pem \
    --embed-certs=true \
    --kubeconfig=admin.kubeconfig

  kubectl config set-context default \
    --cluster=kubernetes-the-kubernetes-way \
    --user=admin \
    --kubeconfig=admin.kubeconfig

  kubectl config use-context default --kubeconfig=admin.kubeconfig
)

[[ -f encryption-config.yaml ]] || {
  ENCRYPTION_KEY=$(head -c 32 /dev/urandom | base64)
  cat > encryption-config.yaml <<EOF
kind: EncryptionConfig
apiVersion: v1
resources:
  - resources:
      - secrets
    providers:
      - aescbc:
          keys:
            - name: key1
              secret: ${ENCRYPTION_KEY}
      - identity: {}
EOF
}

i=0
while [ $i -lt $MASTERS ]; do
  instance=controller-$i
  (
  set -x
  while [[ ! $(gcloud compute ssh ${instance} --command "hostname -s" 2>/dev/null) ]]; do
    echo "waiting for ssh access to ${instance}"
    sleep 5
  done

  gcloud compute scp \
    ca.pem ca-key.pem kubernetes-key.pem kubernetes.pem \
    service-account-key.pem service-account.pem \
    admin.kubeconfig kube-controller-manager.kubeconfig kube-scheduler.kubeconfig \
    encryption-config.yaml \
    $DIR/setup-kubelet.sh \
    ${instance}:~/

  gcloud compute ssh ${instance} -- bash setup-kubelet.sh --public-ip "$KUBERNETES_PUBLIC_ADDRESS"

  )
  ((i++))
done

(
  set -x
  gcloud compute http-health-checks create kubernetes \
    --description "Kubernetes Health Check" \
    --host "kubernetes.default.svc.cluster.local" \
    --request-path "/healthz" || echo skipping...

  gcloud compute firewall-rules create kubernetes-the-kubernetes-way-allow-health-check \
    --network kubernetes-the-kubernetes-way \
    --source-ranges 209.85.152.0/22,209.85.204.0/22,35.191.0.0/16 \
    --allow tcp || echo skipping...

  gcloud compute target-pools create kubernetes-target-pool \
    --http-health-check kubernetes || echo skipping...

  # TODO - support multiple masters
  gcloud compute target-pools add-instances kubernetes-target-pool \
  --instances controller-0 || echo skipping...

  gcloud compute forwarding-rules create kubernetes-forwarding-rule \
    --address "${KUBERNETES_PUBLIC_ADDRESS}" \
    --ports 6443 \
    --region "${REGION}" \
    --target-pool kubernetes-target-pool || echo skipping...
)
